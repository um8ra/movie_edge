{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.mllib.feature import Word2Vec, Word2VecModel\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import h5py\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = os.cpu_count() - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/40208420/how-to-find-hdf5-file-groups-keys-within-python\n",
    "with h5py.File('binarized.hdf') as f:\n",
    "    print(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext('local[{cpus}]'.format(cpus=partitions), 'word2vec')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS\n",
    "LIKED = 'Liked'\n",
    "MOVIE_ID = 'movieId'\n",
    "USER_ID = 'userId'\n",
    "TIMESTAMP = 'Timestamp'\n",
    "TITLE = 'title'\n",
    "GENRE = 'genres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(_df):\n",
    "    _df = _df.drop([TIMESTAMP], axis=1)\n",
    "    _df[MOVIE_ID] = _df.index.get_level_values(MOVIE_ID).astype(str)\n",
    "    return _df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('ml-20m/movies.csv', index_col=MOVIE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trg = pd.read_hdf('binarized.hdf', key='trg')\n",
    "df_trg = df_trg[df_trg[LIKED] == 1]\n",
    "df_trg = df_trg.head(50000) # todo comment out for production\n",
    "df_trg = transform_df(df_trg)\n",
    "\n",
    "df_val = transform_df(pd.read_hdf('binarized.hdf', key='val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "# The most ratings any user has had\n",
    "df_trg_gb = df_trg.groupby([USER_ID])\n",
    "dict_groups_trg = {k: list(v[MOVIE_ID]) for k, v in df_trg_gb}\n",
    "WINDOW_SIZE = df_trg_gb[LIKED].count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_gb = df_val.groupby([USER_ID])\n",
    "dict_groups_val = {k: list(v[MOVIE_ID]) for k, v in df_val_gb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 'learning_rate'\n",
    "VECTOR_SIZE = 'vector_size'\n",
    "MIN_COUNT = 'min_count'\n",
    "param_grid = ParameterGrid({\n",
    "    LEARNING_RATE: [0.025, 0.01, 0.05],\n",
    "    VECTOR_SIZE: [64, 128],\n",
    "    MIN_COUNT: [5, 10, 20]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = sc.parallelize(dict_groups_trg.values(), partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_performance = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in param_grid:\n",
    "    logging.debug('Params: {params}'.format(params=params))\n",
    "    logging.debug('Start Train: {ts}'.format(ts=pd.Timestamp('now')))\n",
    "    \n",
    "    # Constant\n",
    "    word2vec = Word2Vec()\n",
    "    word2vec.setNumPartitions(partitions)\n",
    "    word2vec.setWindowSize(WINDOW_SIZE)\n",
    "    \n",
    "    # Grid\n",
    "    word2vec.setLearningRate(params[LEARNING_RATE])\n",
    "    word2vec.setVectorSize(params[VECTOR_SIZE])\n",
    "    word2vec.setMinCount(params[MIN_COUNT])\n",
    "    \n",
    "    # Fit and save\n",
    "    model = word2vec.fit(document)\n",
    "    logging.debug('Stop Train: {ts}'.format(ts=pd.Timestamp('now')))\n",
    "    outdir = 'w2v_model_pt_{partitions}_mc_{min_count}_lr_{lr}_vs_{vs}.sparkmodel'.format(\n",
    "        partitions=partitions, min_count=params[MIN_COUNT], lr=params[LEARNING_RATE],\n",
    "        vs=params[VECTOR_SIZE]\n",
    "    )\n",
    "    if os.path.isdir(outdir):\n",
    "        shutil.rmtree(outdir)\n",
    "    model.save(sc, outdir)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.transform('1234')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transform(['1234', '1234'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_groups_val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transfor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_synonyms(search_str, num_synonyms):\n",
    "    synonym_list = list()\n",
    "    movie_index = df_movies[df_movies[TITLE].str.match(search_str)]\n",
    "    print(movie_index)\n",
    "    for mi in movie_index.index:\n",
    "        synonym_list.extend([(i, df_movies.loc[int(i[0])][TITLE]) for i in \n",
    "                             list(model.findSynonyms(str(mi), num_synonyms))])\n",
    "    return synonym_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec2 = Word2VecModel.load(sc, 'trained_wor2vec_pyspark.sparkmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_synonyms('.*Matrix.*', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_synonyms('.*Private Ryan.*', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
