{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=50 done\n",
      "k=500 done\n",
      "k=1500 done\n",
      "k=5000 done\n",
      "k=10000 done\n",
      "k=23892 done\n",
      "6\n",
      "(23891, 2)\n",
      "(23891, 2)\n",
      "(23891, 2)\n",
      "(23891, 2)\n",
      "(23891, 2)\n",
      "(23891, 2)\n",
      "                                      title  \\\n",
      "movieId                                       \n",
      "1                          Toy Story (1995)   \n",
      "2                            Jumanji (1995)   \n",
      "3                   Grumpier Old Men (1995)   \n",
      "4                  Waiting to Exhale (1995)   \n",
      "5        Father of the Bride Part II (1995)   \n",
      "\n",
      "                                              genres  \\\n",
      "movieId                                                \n",
      "1        Adventure|Animation|Children|Comedy|Fantasy   \n",
      "2                         Adventure|Children|Fantasy   \n",
      "3                                     Comedy|Romance   \n",
      "4                               Comedy|Drama|Romance   \n",
      "5                                             Comedy   \n",
      "\n",
      "                                                    vector  L0   L1    L2  \\\n",
      "movieId                                                                     \n",
      "1        [0.059872735, -0.36095208, -0.077433385, 0.011...  38  253    86   \n",
      "2        [0.1691944, -0.062943615, -0.10992637, -0.4388...   7  323   568   \n",
      "3        [0.5042098, 0.28392687, -0.12367318, -0.100494...  48  109    75   \n",
      "4        [0.19736828, 0.22314307, -0.60929656, -0.52939...   7  144  1171   \n",
      "5        [0.52236795, 0.23525663, -0.40892157, -0.26716...  48  109    75   \n",
      "\n",
      "           L3    L4     L5        L0x  ...        L1x        L1y        L2x  \\\n",
      "movieId                                ...                                    \n",
      "1        3928   490  17609 -25.121387  ... -26.261216 -17.192878 -24.556549   \n",
      "2        1375  6166  17549 -24.079591  ... -23.398433 -37.803330 -23.793513   \n",
      "3        2308  8729  20506 -19.071078  ... -19.104410 -34.704931 -19.565281   \n",
      "4          35  2975  19635 -24.079591  ... -26.348962 -42.118087 -25.380020   \n",
      "5        2308  8729  12221 -19.071078  ... -19.104410 -34.704931 -19.565281   \n",
      "\n",
      "               L2y        L3x        L3y        L4x        L4y        L5x  \\\n",
      "movieId                                                                     \n",
      "1       -19.140869 -26.546903 -26.316064 -26.546903 -26.316064 -24.818191   \n",
      "2       -38.014708 -23.621806 -37.434528 -23.729606 -36.868994 -23.699334   \n",
      "3       -36.100801 -19.259646 -35.792775 -19.150054 -35.960445 -19.133236   \n",
      "4       -41.287062 -25.380020 -41.287062 -25.443337 -40.919109 -25.145826   \n",
      "5       -36.100801 -19.259646 -35.792775 -19.150054 -35.960445 -19.166872   \n",
      "\n",
      "               L5y  \n",
      "movieId             \n",
      "1       -33.915651  \n",
      "2       -36.924182  \n",
      "3       -35.903725  \n",
      "4       -40.735246  \n",
      "5       -36.017165  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "#%% Loading\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from bokeh import palettes\n",
    "from sqlalchemy import create_engine\n",
    "import pickle\n",
    "\n",
    "fast = True\n",
    "if fast:\n",
    "# Dont' delete these, just comment them out so that when we share the notebook \n",
    "# we don't need to keep remembering where out paths are.\n",
    "    sys.path.append('C:/users/jtay/Desktop/6242/viz proto/bin')\n",
    "    sys.path.append('C:/users/jtay/Desktop/6242/viz proto')\n",
    "#    sys.path.append('/Users/danielklass/Dropbox/GaTech/cse6242_project/FIt-SNE')\n",
    "    from fast_tsne import fast_tsne # O(N) via FFT, see all the comments above...\n",
    "else:\n",
    "    raise NotImplementedError('Set fast == True!')\n",
    "\n",
    "\n",
    "RAND = 4\n",
    "workers = os.cpu_count() - 2\n",
    "MOVIE_ID = 'movieId'\n",
    "TITLE = 'title'\n",
    "RATING = 'rating'\n",
    "VECTOR = 'vector'\n",
    "GENRES = 'genres'\n",
    "MEAN = 'mean'\n",
    "COUNT = 'count'\n",
    "STDDEV = 'std'\n",
    "X = 'x'\n",
    "Y = 'y'\n",
    "CLUSTER = 'cluster'\n",
    "COLOR = 'color'\n",
    "\n",
    "\n",
    "model_filename = 'w2v_vs_64_sg_1_hs_1_mc_1_it_4_wn_32_ng_2_all_data_trg_val_tst.gensim'\n",
    "model = Word2Vec.load(os.path.join('./gensim_models2', model_filename))\n",
    "\n",
    "\n",
    "with open('metadata.pkl', 'rb') as f:\n",
    "    dict_metadata = pickle.load(f)\n",
    "\n",
    "df_movies = pd.read_csv('ml-20m/movies.csv', index_col=MOVIE_ID)\n",
    "\n",
    "def get_movie_vector(i):\n",
    "    try:\n",
    "        return model.wv.get_vector(str(i))\n",
    "    except KeyError:\n",
    "        return np.nan\n",
    "\n",
    "df_movies[VECTOR] = df_movies.index.get_level_values(MOVIE_ID).map(get_movie_vector)\n",
    "df_movies = df_movies[pd.notnull(df_movies[VECTOR])].copy()\n",
    "vectors = df_movies[VECTOR].to_numpy()\n",
    "vectors = np.vstack(vectors)\n",
    "\n",
    "\n",
    "\n",
    "# %% Run the clustering and tsne\n",
    "\n",
    "\n",
    "\n",
    "num_clusters = [50,500,1500,5000,10000,len(vectors)]\n",
    "cluster_list = []\n",
    "for k in num_clusters:\n",
    "    clusterer = AgglomerativeClustering(n_clusters=k,linkage='ward',)\n",
    "    clusterer = clusterer.fit(vectors)\n",
    "    cluster_list.append(clusterer)\n",
    "    print(f'k={k} done')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tsne_result = fast_tsne(vectors, seed=RAND, nthreads=workers)\n",
    "\n",
    "\n",
    "\n",
    "df_movies[X] = tsne_result[:, 0]\n",
    "df_movies[Y] = tsne_result[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "print(len(cluster_list))\n",
    "for clusterer in cluster_list:\n",
    "    print(clusterer.children_.shape)\n",
    "\n",
    "\n",
    "#df_movies = bak.copy() # in case something goes pear shaped\n",
    "for i,clusterer in enumerate(cluster_list):\n",
    "    df_movies[f'L{i}'] =clusterer.labels_\n",
    "bak = df_movies.copy()\n",
    "\n",
    "\n",
    "# %% Get full df\n",
    "df_movies = bak.copy()\n",
    "for level in [f'L{i}' for i in range(6)]:\n",
    "    df_movies[level+'x'] = df_movies.groupby(level)['x'].transform('mean')\n",
    "    df_movies[level+'y'] = df_movies.groupby(level)['y'].transform('mean')\n",
    "del df_movies['x']\n",
    "del df_movies['y']\n",
    "print(df_movies.head())\n",
    "del df_movies['vector']\n",
    "\n",
    "df_output = df_movies.copy()\n",
    "df_output = df_output.rename(columns={\n",
    "    'title': 'movie_title',\n",
    "})\n",
    "df_output.index.rename('movie_id', inplace=True)\n",
    "df_output['embedder'] = model_filename\n",
    "\n",
    "\n",
    "POSTER_URL = 'poster_url'\n",
    "RUNTIME = 'runtime'\n",
    "DIRECTOR = 'director'\n",
    "ACTORS = 'actors'\n",
    "METASCORE = 'metascore'\n",
    "IMDB_RATING = 'imdb_rating'\n",
    "IMDB_VOTES = 'imdb_votes'\n",
    "\n",
    "df_output[POSTER_URL] = df_output.index.map(lambda x: dict_metadata[x]['Poster']).map(\n",
    "    lambda x: None if x == 'N/A' else x)\n",
    "df_output[RUNTIME] = df_output.index.map(\n",
    "    lambda x: dict_metadata[x]['Runtime']).map(\n",
    "    lambda x: x.replace(' min', '')).map(\n",
    "    lambda x: int(x) if x.isdigit() else None)\n",
    "df_output[DIRECTOR] = df_output.index.map(lambda x: dict_metadata[x]['Director']).map(\n",
    "lambda x: '|'.join(x.split(', ')))\n",
    "df_output[ACTORS] = df_output.index.map(lambda x: dict_metadata[x]['Actors']).map(\n",
    "lambda x: x.replace(', ', '|'))\n",
    "df_output[METASCORE] = df_output.index.map(lambda x: dict_metadata[x]['Metascore']).map(\n",
    "    lambda x: int(x) if x.isdigit() else None)\n",
    "df_output[IMDB_RATING] = df_output.index.map(lambda x: dict_metadata[x]['imdbRating']).map(\n",
    "    lambda x: float(x) if x != 'N/A' else None)\n",
    "df_output[IMDB_VOTES] = df_output.index.map(lambda x: dict_metadata[x]['imdbVotes']).map(\n",
    "    lambda x: int(x.replace(',', '')) if x != 'N/A' else None)\n",
    "\n",
    "bak = df_output.copy()\n",
    "\n",
    "# %% Create the dumps we need - output has all of it already\n",
    "from collections import Counter\n",
    "import json\n",
    "df_output = bak.copy()\n",
    "\n",
    "output = {}\n",
    "def mostCommon(series,n=10):\n",
    "    vals = series.tolist()\n",
    "    tmp = '|'.join(vals)\n",
    "    tmp = Counter(tmp.split('|')).most_common(10)\n",
    "    \n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3061959e20fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tmp' is not defined"
     ]
    }
   ],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = create_engine('sqlite:///cse6242_team5/db.sqlite3')\n",
    "\n",
    "for level in range(5):\n",
    "    means = df_output.groupby(f'L{level}')[['L5x','L5y','metascore','imdb_rating']].mean()\n",
    "    means = means.rename(columns={f'L{level}':'ID'})\n",
    "    counts = df_output.groupby(f'L{level}')[['genres','actors']].agg(mostCommon)\n",
    "    counts = counts.applymap(lambda x: json.dumps(x))\n",
    "    tmp = pd.concat([means,counts],1).rename(columns={'L5x':'x','L5y':'y'}).fillna(\"null\")\n",
    "    tmp.index.name = 'cluster_id'\n",
    "    with eng.begin() as con:\n",
    "        tmp.to_sql(f'movie_edge_c{level}', con, if_exists='append')\n",
    "    \n",
    "tmp = df_output.copy().fillna(\"null\")\n",
    "tmp['x'] = tmp.L5x;\n",
    "tmp['y'] = tmp.L5y;\n",
    "\n",
    "tmp = tmp.rename(columns={'movie_id':'ID'})\n",
    "\n",
    "with eng.begin() as con:\n",
    "    tmp.to_sql('movie_edge_movie', con, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
