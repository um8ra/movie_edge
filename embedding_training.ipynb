{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tensorflow import keras as k  # using 2.0.0-rc0\n",
    "import numpy as np\n",
    "import random\n",
    "np.set_printoptions(linewidth=128)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('ml-20m')  # First time using pathlib, pretty neat. \"division\" is cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERID = 'userId'\n",
    "MOVIEID = 'movieId'\n",
    "RATING = 'rating'\n",
    "TITLE = 'title'\n",
    "GENRES = 'genres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv(path / 'ratings.csv', index_col=[USERID, MOVIEID])[RATING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: MOVIEID is not a 0 through X where X is len(df_movies)\n",
    "df_movies = pd.read_csv(path / 'movies.csv', index_col=MOVIEID)\n",
    "# That is why we're extracting the index to give us an ordering\n",
    "df_movies_index = df_movies.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_decoder = {val: ix for ix, val in enumerate(df_movies_index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_users = set(df_ratings.index.get_level_values(USERID))\n",
    "distinct_users_count = len(distinct_users)\n",
    "distinct_movies = set(df_movies.index.get_level_values(MOVIEID))\n",
    "distinct_movies_count = len(distinct_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_one_hot_movie(_i):\n",
    "    _zeros = np.zeros(distinct_movies_count)\n",
    "    _movie_index = movie_id_decoder[_i]\n",
    "    _zeros[_movie_index] = 1.0\n",
    "    return _zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_dict(_dict):\n",
    "    # https://stackoverflow.com/questions/53124979/get-a-random-subset-of-a-dictionary\n",
    "    _memory_limit = 20000\n",
    "    if len(_dict) > _memory_limit: # tune to suit your computer's memory limits\n",
    "        print('Hit limit')\n",
    "        _dict = dict(random.sample(_dict.items(), int(_memory_limit * 0.9))) \n",
    "        print('New Dict Len: {}'.format(len(_dict)))\n",
    "        return _dict\n",
    "    else:\n",
    "        return _dict\n",
    "\n",
    "def form_output(_user_id, _user_data, _dict_cache):  # need something faster... not sure what\n",
    "    _dict_cache = audit_dict(_dict_cache)\n",
    "    \n",
    "    if _user_id in _dict_cache.keys():\n",
    "        return _dict_cache[_user_id], _dict_cache\n",
    "    else:\n",
    "        _calculated_value = _user_data.reindex(df_movies_index).fillna(0.0).to_numpy()\n",
    "        _dict_cache[_user_id] = _calculated_value\n",
    "        return _calculated_value, _dict_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given user and the user's ratings\n",
    "# It returns the user's ratings vector conformed to the movie index \n",
    "# with zeros filling unseen movies\n",
    "# It also returns the caching dictionary which may or may not be updated\n",
    "# This needs to be passed around to avoid globals unfortunately\n",
    "form_output(1, df_ratings.loc[1], {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes a dict of movie_id: one_hot\n",
    "# Recall that the movie_id is not between 0 and len(movies)\n",
    "# So the one_hot incorporates the lookup to translate a movie_id\n",
    "# To the proper index so the vector can actually be len(movies)\n",
    "dict_movie_one_hots = {movie_id: form_one_hot_movie(movie_id) \n",
    "                       for movie_id in df_movies_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has problems. Please help :)\n",
    "\n",
    "batch_size = 128\n",
    "model = k.models.Sequential()\n",
    "model.add(k.layers.Embedding(distinct_movies_count, 64, \n",
    "                             input_length=distinct_movies_count))\n",
    "model.add(k.layers.Flatten())\n",
    "model.add(k.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cache = dict()\n",
    "ix = 0\n",
    "batch_x = list()\n",
    "batch_y = list()\n",
    "for (user_id, movie_id), row in df_ratings.iloc[0:4096].sample(frac=1).items():\n",
    "    movie_one_hot = dict_movie_one_hots[movie_id]\n",
    "    output_vector, dict_cache = form_output(user_id, df_ratings.loc[user_id], dict_cache)\n",
    "    \n",
    "    batch_x.append(movie_one_hot)\n",
    "    batch_y.append(output_vector)\n",
    "    \n",
    "    if len(batch_x) == 128:\n",
    "        batch_x = np.vstack(batch_x)\n",
    "        batch_y = np.vstack(batch_y)\n",
    "        model.fit(x=batch_x, y=batch_y)\n",
    "        batch_x = list()\n",
    "        batch_y = list()\n",
    "        \n",
    "    if ix % 1000 == 0:\n",
    "        print(ix)\n",
    "    ix += 1\n",
    "#     print(user)\n",
    "#     print(movie)\n",
    "#     print(row)\n",
    "#     print(movie_one_hot)\n",
    "#     print(output_vector)\n",
    "#     print(dict_cache)\n",
    "print('done')\n",
    "#     model.fit(movie_one_hot, output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
