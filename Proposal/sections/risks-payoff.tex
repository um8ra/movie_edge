\subsection{Risks and Payoffs?}

The primary risk this project poses is that it may be too agressive in too short of a timeline. We are planning on incorporating many facets learned over the course of our time at Georgia Tech. These include working with graph data, self-teaching machine learning (specifically neural networks), similarity analysis, web development and visualization. Our group views our project as being quite sizable to accomplish. Computational costs may also be a factor since neural nets take a lot time to train, and we have hard deadlines to hit.

Knowing the risks, the rewards are high: we may have a movie recommendation engine that allows us more detail and granularity than Netflix does, and certainly with more transparency since we'll have both the source data and source code. Previously, Netflix allowed people to feed data on a five star scale. In 2017, after deep learning started taking off (Tensorflow was released in 2015), they changed this to "thumbs up" or "thumbs down," a binary choice lacking granularity. We surmise that this is because neural network embeddings are based on one-hot encoded vectors and it was more efficient at Netflix's scale to utilize embeddings than a traditional feed-forward neural network.

As discussed in the Weighted Word2Vec paper (Chang, Lee, Lai), Word2Vec is not the pinnacle of understanding embeddings and there are other techniques that may prove frutiful. The main concept addressed by this paper is that proximity of words should be considered in Word2Vec and that the neural network weights may be purposefully weighted more or less to enable this. Another issue discussed in the paper with Word2Vec is the curse of dimensionality. Rather than having words, we have ratings for movies that can be 1-5 stars. If we were to make movieA-1star a "word" this means that each movie has 11 options (0 to 5 by 0.5 step). This would drastically increase the size of the embedding space. Our approach, by not using a traditional one-hot embedding will allow us to keep dimensions low, as the Weighted Word2Vec paper addresses. However this may cost us compute in that many modern speed improvements capitalize on the 1-hot nature of embeddings. We hope this approach will let us more accurately represent movie ratings in an embedding space. If the compute cost is too high (a risk) we may need to fall back to the one-hot method with 11x feature space. Or round to the nearest star.

Upon finding similar movies and their projected ratings based on user input, a user could even find other users with similar taste and explore their likes and dislikes. In essence, we are allowing for two outcomes: movie rating prediction (primary), and user similarity prediction (stretch goal). Seeing as humans still are the most computationally powerful neural nets on the planet, this "user exploration" may be a very powerful approach to recommendations.

While our end users may be a bunch of computer scientists for the moment, handing someone a vector and stating with excitement that "here are your recommendations, how exciting!" is not likely to yield an ecstatic customer. We will visualize the output to make our end product more usable by people that aren't CS or Analytics grad students.
