\subsection{Collaborative Filtering Recommender Systems}

Early CF systems were driven by nearest-neighbor similarity methods \cite{herlocker1999algorithmic}, \cite{smith2017two}, weighting similarity between user vectors of ratings. While neighborhood-based CF are easy to implement, they are not as accurate as more complex models.

Item-based CF methods are driven by item-to-item similarity. Amazon constructed a similar-items table by finding items that people tend to buy together \cite{linden2003amazon}, \cite{smith2017two}. Scalability is achieved via offline pre-processing. However, they focus on real-time query and forgo user-centric interpretability. 

The Netflix Prize introduced new CF algorithms based on matrix factorization (MF) \cite{funk2006netflix}. User-item ratings are viewed as a matrix where rows represent users and columns movies: ratings are the sparse matrix entries. MF seeks to estimate unknown ratings by approximating with a low-rank decomposition. MF is highly accurate for movie rating prediction, and it remains the predominant CF technique today \cite{koren2008factorization}. 

One shortcoming of MF is that only user-item ratings are taken into account. Rendle \cite{rendle2012factorization} developed Factorization Machines (FM), a supervised learning algorithm which models feature interactions with factorized parameters.  FMs can be seen as a generalization of MF which can easily incorporate side-channel features along with user-item ratings matrix for greater accuracy while reducing training time.

Vector representation of words is widely adopted in Natural Language Processing (NLP). Two Word2vec architectures, Continuous Bag-of-Words (CBOW) and Skim-gram models \cite{mikolov2013efficient},  \cite{mikolov2013distributed}, \cite{rong2014word2vec} were introduced to learn embeddings from words in sentences. The embeddings capture contextual similarity. This can be applied to user-item interaction data \cite{ozsoy2016word}. Training Word2vec takes advantage of one-hot-encoding (OHE). However, movie ratings are often not binary, increasing architectural complexity.

\subsection{Interactive Recommendations}

Most RS are not interactive. MetaLens \cite{schafer2002meta}gives users session-specific control over the recommendation process, improving user satisfaction. MetaLens is limited to filtering or sorting the list of recommendations with user-specified criteria. The potential filters are hard-coded and reflect user constraints rather than content preferences. 

MovieExplorer \cite{taijala2018movieexplorer}, which incorporates user feedback in the RS, is closest in similarity to MovieEdge. MovieExplorer allows the user to navigate the model's latent factor space by expressing their session-specific preferences for movies.  As the session progresses, MovieExplorer presents better recommendations. MovieExplorer’s interactive exploration paradigm increased user satisfaction. However, MovieExplorer asks users to navigate the high dimensional latent factor space without a visual reference. 

\subsection{Visualization of Embedding Spaces}

t-Stochastic Neighbor Embedding \mbox{t-SNE} \cite{maaten2008visualizing} projects high dimensional feature vectors into 2-3D visualizations. \mbox{t-SNE} computes similarity scores between observations in the high dimensional feature space and finds a low dimensional embedding: points which are close in high dimensional space remain close in the projected space. \mbox{t-SNE} is nonlinear and adaptive to the data distribution. \mbox{t-SNE} is known for producing high-quality visualizations, albeit at the cost of hyperparameter tuning and computation. Using \mbox{t-SNE} can be difficult, and much care must be taken with interpretation \cite{wattenberg2016how}.

Taking the gradient of the \mbox{t-SNE} cost function with respect to the coordinates in the embedding space can be compute expensive.  Acceleration \mbox{t-SNE} through tree-based algorithms like the Barnes-Hut approximation \cite{van2014accelerating} can help to “summarize” observations.  

Embedding Projector \cite{smilkov2016embedding} leverages \mbox{t-SNE} to visualize high dimensional data. We will adopt this approach in the high dimensional taste space of our CF model, augmenting with supplemental data and user interactivity. 

Our primary dataset is MovieLens \cite{harper2016movielens}, which includes over 27,000 unique movies. Ward Hierarchical clustering \cite{ward1963hierarchical} will reduce the visual load:  its hierarchical nature will allow users to zoom in and out of the visualization as we dynamically expand and collapse the clusters.

\subsection{Evaluating Recommender Systems}

RS has traditionally been evaluated on accuracy. \cite{herlocker2004evaluating} proposed an alternative metric, Serendipity, the tendency for a RS to produce  “interesting” recommendations. By visualizing the latent CF model space during exploration, MovieEdge greatly increases the chance of a serendipitous encounter.
